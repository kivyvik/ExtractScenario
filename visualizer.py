from typing import List

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.patches import Polygon

from EgoTrajectory import EgoTrajectory

class Visualizer:
    def __init__(self, ego_traj: EgoTrajectory, lane_boundaries: List):
        self.ego_traj = ego_traj
        self.lane_boundaries = lane_boundaries

    def get_ego_rectangle(self, ego_pos, heading, car_length=4.5, car_width=2.0):
        ego_pos = np.array(ego_pos)
        # Unit vector along the car's heading
        v = np.array([np.cos(heading), np.sin(heading)])
        # Perpendicular (to the left) for the width direction
        v_perp = np.array([-np.sin(heading), np.cos(heading)])

        # The ego_pos is the front-center. So:
        front_left = ego_pos + (car_width / 2) * v_perp
        front_right = ego_pos - (car_width / 2) * v_perp
        # Rear center is located car_length behind the front
        back_center = ego_pos - car_length * v
        back_left = back_center + (car_width / 2) * v_perp
        back_right = back_center - (car_width / 2) * v_perp

        # Return polygon corners in order (to draw a closed rectangle)
        return np.array([front_left, front_right, back_right, back_left])

    def transform_to_local(self, points, ego_position, offset=np.array([10, 0])):
        """
        points: array of (x,y) points in global coordinates
        ego_position: the current ego position (global)
        offset: the translation to place the ego vehicle in the plot window.
        """
        points = np.array(points)
        return points - np.array(ego_position) + offset

    def create_video(self, ego_traj, lane_boundaries, view_offset=np.array([10, 0]), video_filename='demo.mp4'):
        """
        Create a video of the ego trajectory and nearby lane boundaries.

        The video is generated by interpolating the ego state at a fixed frame rate.

        :param ego_traj: Instance of EgoTrajectory.
        :param lane_boundaries: List of lane boundary polylines (each polyline is a list of (x, y) points).
        :param view_offset: Offset used to translate the ego into view.
        :param video_filename: Output video file name.
        """
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.set_xlim(0, 80)  # x: 0 to 80 (length of view)
        ax.set_ylim(-15, 15)  # y: -15 to 15 (width of view)
        ax.set_aspect('equal')
        ax.set_title('Ego Trajectory and Lane Boundaries')

        # Create line objects for lane boundaries
        lane_lines = []
        for polyline in lane_boundaries:
            line, = ax.plot([], [], 'k-', linewidth=2)
            lane_lines.append(line)

        # Create a patch for the ego car (as a rectangle)
        ego_patch = Polygon([[0, 0]], closed=True, fc='blue', ec='black', alpha=0.7)
        ax.add_patch(ego_patch)

        # Text display for the current simulation time
        time_text = ax.text(0.02, 0.95, '', transform=ax.transAxes)

        # Choose a fixed frame rate (e.g., 30 FPS)
        fps = 30
        total_duration = ego_traj.timestamps[-1] - ego_traj.timestamps[0]
        num_frames = int(total_duration * fps)
        # Generate evenly spaced target times based on the simulation timestamps
        frame_times = np.linspace(ego_traj.timestamps[0], ego_traj.timestamps[-1], num_frames)

        def init():
            for line in lane_lines:
                line.set_data([], [])
            ego_patch.set_xy([[0, 0]])
            time_text.set_text('')
            return lane_lines + [ego_patch, time_text]

        def animate(i):
            target_time = frame_times[i]
            state = ego_traj.interpolate(target_time)
            if state is None:
                return lane_lines + [ego_patch, time_text]

            # Unpack interpolated state: (x, y, speed, heading)
            x, y, speed, heading = state
            ego_pos = (x, y)

            # Update lane boundaries in an ego-centric view
            for j, polyline in enumerate(lane_boundaries):
                polyline = np.array(polyline)
                local_polyline = self.transform_to_local(polyline, ego_pos, offset=view_offset)
                lane_lines[j].set_data(local_polyline[:, 0], local_polyline[:, 1])

            # Update the ego car rectangle based on its interpolated state
            rect_global = self.get_ego_rectangle(ego_pos, heading)
            rect_local = self.transform_to_local(rect_global, ego_pos, offset=view_offset)
            ego_patch.set_xy(rect_local)

            time_text.set_text(f"Time: {target_time:.2f} s")

            return lane_lines + [ego_patch, time_text]

        # Create animation without using sleep, based solely on interpolated frames
        ani = animation.FuncAnimation(fig, animate, frames=num_frames,
                                      init_func=init, blit=True, interval=1000 / fps)

        # Save the animation to video (using FFmpeg if available, otherwise a GIF writer)
        Writer = animation.writers['ffmpeg'] if 'ffmpeg' in animation.writers.list() else animation.PillowWriter
        writer = Writer(fps=fps)
        ani.save(video_filename, writer=writer)
        plt.close(fig)
        print(f"Video saved as {video_filename}")

    def visualize(self):
        self.create_video(self.ego_traj, self.lane_boundaries, view_offset=np.array([10, 0]), video_filename='demo.mp4')